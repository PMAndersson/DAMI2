{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DAMI 2 project maan5745"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "training_data = pd.read_csv(\"datasets/aps_failure_training_set.csv\",skiprows=20, na_values='na')\n",
    "test_data = pd.read_csv(\"datasets/aps_failure_test_set.csv\",skiprows=20, na_values='na')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_data.shape)\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_data.shape)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zeros in the training set\n",
    "zeros_train = (training_data == 0).sum()/len(training_data)\n",
    "plt.figure(figsize=(25,5))\n",
    "zeros_train.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zeros in the test set\n",
    "zeros_test = (test_data == 0).sum()/len(test_data)\n",
    "plt.figure(figsize=(25,5))\n",
    "zeros_test.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_training = (training_data.isna().sum())/len(training_data)\n",
    "plt.figure(figsize=(25,5))\n",
    "nan_training.plot.bar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(training_data['class'].unique(),training_data['class'].value_counts())\n",
    "plt.title('Distribution of Class Labels')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "print('count of ones:',training_data['class'].value_counts()[1])\n",
    "print('count of zeros: ',training_data['class'].value_counts()[0])\n",
    "print('ratio ones/zeros: ',training_data['class'].value_counts()[1]/training_data['class'].value_counts()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(test_data['class'].unique(),test_data['class'].value_counts())\n",
    "plt.title('Distribution of Class Labels')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "print('count of ones: ',test_data['class'].value_counts()[1])\n",
    "print('count of zeros: ',test_data['class'].value_counts()[0])\n",
    "print('ratio ones/zeros: ',test_data['class'].value_counts()[1]/test_data['class'].value_counts()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "std_training = training_data.std()\n",
    "std_training.sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data['cd_000'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop feature cd_000 due to constant values\n",
    "training_data.drop('cd_000',axis =1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NaN according to threshold = 0,5\n",
    "\n",
    "threshold = len(training_data)*0.5\n",
    "\n",
    "training_data_dropped = training_data.dropna(axis=1, thresh=threshold)\n",
    "\n",
    "\n",
    "col_diff = test_data.columns.difference(training_data_dropped.columns)\n",
    "test_data_dropped = test_data.drop(col_diff, axis =1)\n",
    "training_data_dropped.info(), test_data_dropped.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_dropped.columns[training_data_dropped.isna().any()].to_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing remaining NaN values\n",
    "\n",
    "training_data_dropped_imputed = training_data_dropped.copy()\n",
    "training_data_dropped_imputed.drop('class', axis =1, inplace=True)\n",
    "columns = list(training_data_dropped.columns)\n",
    "columns.pop(0)\n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "imputer.fit(training_data_dropped_imputed)\n",
    "training_data_dropped_imputed = imputer.transform(training_data_dropped_imputed)\n",
    "training_data_dropped_imputed =pd.DataFrame(training_data_dropped_imputed, columns=columns)\n",
    "\n",
    "training_data_dropped_imputed.columns[training_data_dropped_imputed.isna().any()].to_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dropped_imputed = test_data_dropped.copy()\n",
    "test_data_dropped_imputed.drop('class', axis =1, inplace=True)\n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "imputer.fit(test_data_dropped_imputed)\n",
    "test_data_dropped_imputed = imputer.transform(test_data_dropped_imputed)\n",
    "test_data_dropped_imputed =pd.DataFrame(test_data_dropped_imputed, columns=columns)\n",
    "\n",
    "test_data_dropped_imputed.columns[test_data_dropped_imputed.isna().any()].to_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the final version of the data set for the classification \n",
    "\n",
    "X_train = training_data_dropped_imputed.copy()\n",
    "y_train = training_data_dropped['class']\n",
    "y_train.replace({'neg': 0, 'pos': 1}, inplace=True)\n",
    "\n",
    "X_test = test_data_dropped_imputed.copy()\n",
    "y_test = test_data_dropped['class']\n",
    "y_test.replace({'neg': 0, 'pos': 1}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest within the genetic algo using the Scania cost function for evaluation\n",
    "\n",
    "from geneticalgorithm import geneticalgorithm as ga\n",
    "\n",
    "def scania_cost_func(X):\n",
    "\n",
    "    #n_est = int(n_est)\n",
    "    #maxdepth = int(maxdepth)\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators = int(X[0]), max_depth = X[1], random_state = 123)\n",
    "    rf.fit(X_train, y_train)\n",
    "        \n",
    "    true = y_test\n",
    "    pred = rf.predict(X_test)\n",
    "\n",
    "    a = 0\n",
    "    b = 0\n",
    "    c = 0\n",
    "    d = 0\n",
    "\n",
    "    for i in range(len(true)):\n",
    "        if ((true[i] == 1) & (pred[i] == 1)):\n",
    "            a = a + 1\n",
    "        elif ((true[i] == 1) & (pred[i] == 0)):\n",
    "            b = b + 1\n",
    "        elif ((true[i] == 0) & (pred[i] == 1)):\n",
    "            c = c + 1\n",
    "        elif ((true[i] == 0) & (pred[i] == 0)):\n",
    "            d = d + 1\n",
    "    \n",
    "    cost = c*10+b*500\n",
    "\n",
    "    return cost\n",
    "algorithm_param = {'max_num_iteration': 100,\\\n",
    "                   'population_size':100,\\\n",
    "                   'mutation_probability':0.1,\\\n",
    "                   'elit_ratio': 0.01,\\\n",
    "                   'crossover_probability': 0.5,\\\n",
    "                   'parents_portion': 0.3,\\\n",
    "                   'crossover_type':0.5,\\\n",
    "                   'max_iteration_without_improv':None}\n",
    "\n",
    "varbound=np.array([[2,30],[1,10]])\n",
    "#vartype=np.array([['int'],['int']])\n",
    "model=ga(function=scania_cost_func,dimension=2,variable_type='int',variable_boundaries=varbound,function_timeout=40)\n",
    "\n",
    "model.run()\n",
    "convergence=model.report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the confusion matrix for the best hyperparamters\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators = 19, max_depth = 10, random_state = 123)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
